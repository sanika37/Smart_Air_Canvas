# 🖐️ Smart Air Canvas

**Redefining Digital Workspaces with Intelligent Recognition and Creative Tools ( A Hand Gesture Controlled Digital Blackboard )**

---

## ✨ Overview

**Smart Air Canvas** is an innovative, gesture-controlled digital blackboard that transforms hand motions into powerful input mechanisms. Designed for education, accessibility, and creativity, this system leverages computer vision, deep learning, and AI-driven tools to enable users to write, draw, calculate, translate, and more — all without touching a single surface.

---

## 🎯 Features

* 🖌️ **Air Drawing**: Draw and write mid-air using just your index finger.
* 🔠 **Multilingual Character Recognition**: Supports English and Devanagari (Hindi/Marathi).
* 🔤 **Word-Level Recognition**: Converts drawn words into digital text.
* 🧠 **POS Tagging & Grammar Analysis**: Helps analyze sentence structure.
* 🔄 **Real-time Translation & TTS**: Translate between English, Hindi, and Marathi with speech output.
* ➗ **Virtual Calculator**: Solve handwritten equations mid-air.
* 🔺 **Shape Recognition**: Recognizes basic geometric shapes.
* 🗣️ **Voice Commands**: Control the interface using speech.
* 📤 **Upload & Annotate Images**: Import images and draw on top.
* ♿ **Accessibility-First Design**: Ideal for users with motor or speech impairments.
* 📚 **Educational Mode**: Tailored tools for interactive learning.
* 🎮 **Gaming & AR Ready**: Gesture-based game control prototypes included.

---

## 🔧 Tech Stack

* **Languages**: Python 3.9
* **Libraries/Frameworks**:

  * OpenCV, MediaPipe – Real-time hand tracking and gesture recognition
  * TensorFlow + Keras – CNNs for character/shape recognition
  * Pygame – GUI rendering
  * Google GenAI – Contextual text generation and translation
  * TTS APIs – Text-to-speech functionality
* **Datasets**: MNIST, EMNIST, Devanagari Character Dataset, Custom Shape Set
* **Dev Tools**: Anaconda, Overleaf (Documentation), Git, Jupyter

---

## 🏗️ System Architecture

1. **Real-Time Input**: Webcam captures hand motion.
2. **Gesture Recognition**: MediaPipe detects and tracks hand landmarks.
3. **Drawing Engine**: Converts gestures into strokes on a virtual canvas.
4. **ML Models**: Classify characters, shapes, digits using CNNs.
5. **Voice/Translation Layer**: Adds speech recognition and multilingual support.
6. **Output Layer**: Displays text, calculations, translations, and speaks the result.

---

## 👩‍💻 Authors

* Ritika Bist 
* Sanika Ghag 
* Ipshika Anand 

**Thank you for visiting our project!**
