# ğŸ–ï¸ Smart Air Canvas

**Redefining Digital Workspaces with Intelligent Recognition and Creative Tools ( A Hand Gesture Controlled Digital Blackboard )**

---

## âœ¨ Overview

**Smart Air Canvas** is an innovative, gesture-controlled digital blackboard that transforms hand motions into powerful input mechanisms. Designed for education, accessibility, and creativity, this system leverages computer vision, deep learning, and AI-driven tools to enable users to write, draw, calculate, translate, and more â€” all without touching a single surface.

---

## ğŸ¯ Features

* ğŸ–Œï¸ **Air Drawing**: Draw and write mid-air using just your index finger.
* ğŸ”  **Multilingual Character Recognition**: Supports English and Devanagari (Hindi/Marathi).
* ğŸ”¤ **Word-Level Recognition**: Converts drawn words into digital text.
* ğŸ§  **POS Tagging & Grammar Analysis**: Helps analyze sentence structure.
* ğŸ”„ **Real-time Translation & TTS**: Translate between English, Hindi, and Marathi with speech output.
* â— **Virtual Calculator**: Solve handwritten equations mid-air.
* ğŸ”º **Shape Recognition**: Recognizes basic geometric shapes.
* ğŸ—£ï¸ **Voice Commands**: Control the interface using speech.
* ğŸ“¤ **Upload & Annotate Images**: Import images and draw on top.
* â™¿ **Accessibility-First Design**: Ideal for users with motor or speech impairments.
* ğŸ“š **Educational Mode**: Tailored tools for interactive learning.
* ğŸ® **Gaming & AR Ready**: Gesture-based game control prototypes included.

---

## ğŸ”§ Tech Stack

* **Languages**: Python 3.9
* **Libraries/Frameworks**:

  * OpenCV, MediaPipe â€“ Real-time hand tracking and gesture recognition
  * TensorFlow + Keras â€“ CNNs for character/shape recognition
  * Pygame â€“ GUI rendering
  * Google GenAI â€“ Contextual text generation and translation
  * TTS APIs â€“ Text-to-speech functionality
* **Datasets**: MNIST, EMNIST, Devanagari Character Dataset, Custom Shape Set
* **Dev Tools**: Anaconda, Overleaf (Documentation), Git, Jupyter

---

## ğŸ—ï¸ System Architecture

1. **Real-Time Input**: Webcam captures hand motion.
2. **Gesture Recognition**: MediaPipe detects and tracks hand landmarks.
3. **Drawing Engine**: Converts gestures into strokes on a virtual canvas.
4. **ML Models**: Classify characters, shapes, digits using CNNs.
5. **Voice/Translation Layer**: Adds speech recognition and multilingual support.
6. **Output Layer**: Displays text, calculations, translations, and speaks the result.

---

## ğŸ‘©â€ğŸ’» Authors

* Ritika Bist 
* Sanika Ghag 
* Ipshika Anand 

**Thank you for visiting our project!**
